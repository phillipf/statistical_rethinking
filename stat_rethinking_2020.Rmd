---
title: "Rethinking Stats"
output: html_document
---

```{r}

# devtools::install_github("stan-dev/cmdstanr")

# cmdstanr::check_cmdstan_toolchain(fix = TRUE)
# cmdstanr::install_cmdstan()

# install.packages(c("coda","mvtnorm","devtools","loo","dagitty"))
# devtools::install_github("rmcelreath/rethinking")
```

##Chapter two: Small Worlds and Large Worlds

```{r setup, include=FALSE}

grid_size <- 100

library(rethinking)

source(here::here('R', 'utils.R'))

library(lemon)
knit_print.data.frame <- lemon_print

```

```{r}

calc_posterior( 6 , 9 , prior = rep(1, grid_size), grid.size = grid_size )

```

```{r}
prior <- ifelse(p_grid < 0.5, 0, 1)

calc_posterior( 6 , 9 , prior, grid.size=grid_size )

prior <- exp( -5*abs( p_grid - 0.5 ) )

calc_posterior( 6 , 9 , prior, grid.size=grid_size )
```


```{r}

# define prior
prior <- prior
# compute likelihood at each value in grid
likelihood <- dbinom(1, size = 1, prob = 0.3)
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
```

```{r}
# compare the quadratic approximation to analytical calculation
library(rethinking)
globe.qa <- quap(
  alist(
    W ~ dbinom( W+L ,p) , # binomial likelihood
    p ~ dunif(0,1) # uniform prior
  ) ,
  data=list(W=6,L=3) )
# display summary of quadratic approximation
precis( globe.qa )

# analytical calculation
W <- 6
L <- 3
curve( dbeta( x , W+1 , L+1 ) , from=0 , to=1 )
# quadratic approximation
curve( dnorm( x , 0.67 , 0.16 ) , lty=2 , add=TRUE )

```

```{r}
n_samples <- 1000
p <- rep( NA , n_samples )
p[1] <- 0.5
W <- 6
L <- 3
for ( i in 2:n_samples ) {
  p_new <- rnorm( 1 , p[i-1] , 0.1 )
  if ( p_new < 0 ) p_new <- abs( p_new )
  if ( p_new > 1 ) p_new <- 2 - p_new
  q0 <- dbinom( W , W+L , p[i-1] )
  q1 <- dbinom( W , W+L , p_new )
  p[i] <- ifelse( runif(1) < q1/q0 , p_new , p[i-1] )
}

dens( p , xlim=c(0,1) )
curve( dbeta( x , W+1 , L+1 ) , lty=2 , add=TRUE )

```

```{r exercises}
#Q 2M1
#(1) W, W, W
calc_posterior( 3 , 3 , prior = rep(1, grid_size), grid.size=grid_size )
#(2) W, W, W, L
calc_posterior( 3 , 4 , prior = rep(1, grid_size), grid.size=grid_size )
#(3) L, W, W, L, W, W, W
calc_posterior( 5 , 7 , prior = rep(1, grid_size), grid.size=grid_size )

# Q 2M2

prior <- ifelse( p_grid < 0.5 , 0 , 1 )

#(1) W, W, W
calc_posterior( 3 , 3 , prior, grid.size=grid_size )
#(2) W, W, W, L
calc_posterior( 3 , 4 , prior, grid.size=grid_size )
#(3) L, W, W, L, W, W, W
calc_posterior( 5 , 7 , prior, grid.size=grid_size )

# Q 2M3

# Pr(Earth|Land) = Pr(Land|Earth) * Pr(Earth) / Pr(Land)
0.3 * 0.5 / ((1 + 0.3) / 2)

# Q 2M4


```

```{r exercises}


```

##Chapter three

```{r}
p_grid <- seq(from = 0, to = 1, length.out = 1000)
prior <- rep(1, 1000)
likelihood <- dbinom(6, size = 9, prob = p_grid)
unstd.posterior <- likelihood * prior
posterior <- unstd.posterior / sum(posterior)

sample.size <- 1e4

set.seed(100)
samples <- sample(p_grid, prob = posterior, size = sample.size, replace = TRUE)
```


```{r}
plot(p_grid, posterior)

plot(samples)
```

```{r}
library(rethinking)

dens(samples)
```

### Intervals of defined boundaries

### How much posterior probability lies below some parameter value?

```{r}
# add up posterior probability where p < 0.5
sum(posterior[p_grid < 0.5])

# the same calculation, using samples from the posterior
sum(samples < 0.5) / sample.size
```

### How much posterior probability lies between two parameter values?

```{r}
# how much posterior probability lies between 0.5 and 0.75:

sum(samples > 0.5 & samples < 0.75) / sample.size
```

### Intervals of defined mass

```{r}
# you want to know the boundaries of the lower 80% posterior probability. You know this interval starts at p = 0. To find out where it stops, think of the samples as data and ask where the 80th percentile lies.

quantile(samples, 0.8)

# Similarly, the middle 80% interval lies between the 10th percentile and the 90th percentile. These boundaries are found using the same approach

quantile(samples, c(0.1, 0.9))
```


### 3E1. How much posterior probability lies below p = 0.2?
### 3E2. How much posterior probability lies above p = 0.8?
### 3E3. How much posterior probability lies between p = 0.2 and p = 0.8?

```{r}
`3E1` <- sum(posterior[p_grid < 0.2])
`3E2` <- sum(posterior[p_grid > 0.8])
`3E3` <- sum(posterior[p_grid > 0.2 & p_grid < 0.8])

`3E1` + `3E2` + `3E3`
```

### 3E4. 20% of the posterior probability lies below which value of p?
### 3E5. 20% of the posterior probability lies above which value of p?

```{r}
quantile(samples, 0.2)
quantile(samples, 0.8)
```

### 3E6. Which values of p contain the narrowest interval equal to 66% of the posterior probability?
### 3E7. Which values of p contain 66% of the posterior probability, assuming equal posterior probability both below and above the interval?

```{r}

HPDI(samples, prob = 0.66)

PI(samples, prob = 0.66)
```

### 3M1. Suppose the globe tossing data had turned out to be 8 water in 15 tosses. Construct the posterior distribution, using grid approximation. Use the same flat prior as before.

```{r}
n_water <- 8
n <- 15
grid.size <- 1e4

calc_posterior(n_water, n, rep(1, grid.size), grid.size)
```

### 3M2. Draw 10,000 samples from the grid approximation from above. Then use the samples to calculate the 90% HPDI for p.

```{r}

sample.size <- 1e4

set.seed(100)
samples <- sample(p_grid, prob = posterior, size = sample.size, replace = TRUE)

HPDI(samples, 0.9)
```

### 3M3. Construct a posterior predictive check for this model and data. This means simulate the distribution of samples, averaging over the posterior uncertainty in p. What is the probability of observing 8 water in 15 tosses?

```{r}

w <- rbinom( 1e4 , size=15 , prob=samples )

simplehist( w )

p <- table(w)/1e4

p[9]

```

### 3M4. Using the posterior distribution constructed from the new (8/15) data, now calculate the probability of observing 6 water in 9 tosses.

```{r}

w <- rbinom( 1e4 , size=9 , prob=samples )

simplehist( w )

p <- table(w)/1e4

p[7]

```

### 3M5. Start over at 3M1, but now use a prior that is zero below p = 0.5 and a constant above p = 0.5. This corresponds to prior information that a majority of the Earth’s surface is water. Repeat each problem above and compare the inferences. What difference does the better prior make? If it helps, compare inferences (using both priors) to the true value p = 0.7.

```{r}

n_water <- 8
n <- 15
grid.size <- 1e4

prior <- ifelse( p_grid < 0.5 , 0 , 1 )

calc_posterior( n_water, n, prior, grid.size )

samples <- sample( p_grid, size=grid.size, prob=posterior, replace = T )

HPDI( samples, 0.9 )

# 3M3

w <- rbinom( 1e4 , size=15 , prob=samples )

simplehist( w )

p <- table(w)/1e4

p[9]

# 3M4

w <- rbinom( 1e4 , size=9 , prob=samples )

simplehist( w )

p <- table(w)/1e4

p[7]

```

### 3M6 *

```{r}

quantile( samples , c(0.99, 1) )

PI( samples, prob=0.99 )

```

### 3H1

```{r}

data(homeworkch3)

n_boys <- sum(birth1) + sum(birth2)
n_births <- 200
grid.size <- 1e4

prior <- rep(1,grid.size)

calc_posterior( n_boys, n_births, prior, grid.size )

# the value of one maximises the posterior probability of a birth being a boy
##Chapter four

### coin flipping on the football pitch
```


```{r}

# runif(16, -1, 1) = uniform distribution between -1 and 1 with 16 observations

pos <- replicate( 1000 , sum( runif(16,-1,1) ) )

plot(density(pos))

```

### 3H2

```{r}

samples <- sample( p_grid, size=1e4, replace=T, prob=posterior )

HPDI( samples, prob=0.5 )
HPDI( samples, prob=0.89 )
HPDI( samples, prob=0.97 )

```

### 3H3

```{r}

b <- rbinom( 1e4 , size=200 , prob=samples )
simplehist( b )

p <- table(b)/1e4

p

dens(b)

#does the model include 111 boys as a central likely outcome? no, the model is skewed towards 200 boys in 200 births

```



### 3H4

```{r}

n_boys <- sum(birth1)
n_births <- 100
grid.size <- 1e4

calc_posterior( n_boys, n_births, prior = rep(1, grid.size), grid.size )

samples <- sample( p_grid, size=1e4, replace=T, prob=posterior )

b <- rbinom( 1e4 , size=100 , prob=samples )
simplehist ( b )
dens( b )

```

### 3H5

```{r}

n_boys <- birth2[birth1 == 0]
sum(birth1 == 0)

```


#Chapter four

##prior predictive checks

###how do you values for the mean and standard deviation of a guassian likelihood distribution?
####this depends on the context and problem. E.g. when trying to model human height
####mean - what's a reasonable mean height range for a human?
####standard deviation - when you increase the standard deviation you 'flatten' a gaussian distribution i.e. you 'spread' the probability density over a 
####greater range of values. i.e. a standard deviation of 50cm implies that height lies within 100cm of the average height

###how do you choose values for the mean and standard deviation of a guassian prior?
####what range of values would you expect 95% of your probability mass to fall between? 
####e.g. for human height - 178 +- 40cm, therefore, mean = 178 and standard deviation of 20
####how do you values for the

```{r}

#plot the priors individually

#hi ∼ Normal(µ, σ)
#µ ∼ Normal(178, 20) #AKA - a broad Guassian prior, centred on 178cm, with 95% probabilty between 178+-40cm. Seems reasonable for human height.
#σ ∼ Uniform(0, 50) #a flat prior just constrains sigma to have a positive probabilty between min and max. A uniform prior of min (0) and max (50) 

curve( dnorm( x , 178 , 20 ) , from=100 , to=250 )

curve( dunif( x , 0 , 100 ) , from=-10 , to=110 ) 

sample_mu <- rnorm( 1e4 , 178 , 20 )
sample_sigma <- runif( 1e4 , 0 , 50 )
prior_h <- rnorm( 1e4 , sample_mu , sample_sigma )
dens( prior_h )

```

##Grid approximation of the posterior distribution
###for any real problem you always estimate/approximate the posterior distrubtion using other methods e.g. quadratic approximation. However, its good
###to understand the target of the estimates using the brute force method first i.e. grid approximation


```{r}

mu.list <- seq( from=150, to=160 , length.out=100 )
sigma.list <- seq( from=7 , to=9 , length.out=100 )
post <- expand.grid( mu=mu.list , sigma=sigma.list )
post$LL <- sapply( 1:nrow(post) , function(i) sum(
dnorm( d2$height , post$mu[i] , post$sigma[i] , log=TRUE ) ) )
post$prod <- post$LL + dnorm( post$mu , 178 , 20 , TRUE ) +
dunif( post$sigma , 0 , 50 , TRUE )
post$prob <- exp( post$prod - max(post$prod) )

```

```{r}
contour_xyz( post$mu , post$sigma , post$prob )
image_xyz( post$mu , post$sigma , post$prob )

```



```{r}

### 4E1. In the model definition below, which line is the likelihood?
yi ∼ Normal(µ, σ)
µ ∼ Normal(0, 10)
σ ∼ Exponential(1)
### 4E2. In the model definition just above, how many parameters are in the posterior distribution?

```{r}
#4E1
yi <- "likelihood"
µ <- "µ prior"
σ <- "σ prior"

#4E2
# two parameters (µ and σ) in the posterior distribution

```

### 4E. Using the model definition above, write down the appropriate form of Bayes’ theorem that includes the proper likelihood and priors.

Bayes' theorem = probability of the data * prior / average probability of the data

Normal(µ, σ) * Normal(0, 10) * σ ∼ Exponential(1) /
sum(Normal(µ, σ) * Normal(0, 10) * σ ∼ Exponential(1))

```{r}

#what is bayes' theorem?
# E.g. calculating the pr of 6 waters in 9 tosses
w <- 6; n <- 9;
p_grid <- seq(from=0,to=1,length.out=100)
posterior <- dbinom(w,n,p_grid)*dunif(p_grid,0,1)
posterior <- posterior/sum(posterior)

# E.g. calculating the probabilty of a person being a vampire if they test positive to a vampirism test

Pr_Positive_Vampire <- 0.95
Pr_Positive_Mortal <- 0.01
Pr_Vampire <- 0.001
Pr_Positive <- Pr_Positive_Vampire * Pr_Vampire +
Pr_Positive_Mortal * ( 1 - Pr_Vampire )
( Pr_Vampire_Positive <- Pr_Positive_Vampire*Pr_Vampire / Pr_Positive )



```

##4M1. For the model definition below, simulate observed y values from the prior (not the posterior). I.e. Prior predictive check
yi ∼ Normal(µ, σ)
µ ∼ Normal(0, 10)
σ ∼ Exponential(1)

##4M2. Translate the model just above into a quap formula.

```{r}

#4M1

sample_mu <- rnorm( 1e4 , 0 , 10 )
sample_sigma <- rexp( 1e4 , 1 )
prior_y <- rnorm( 1e4 , sample_mu , sample_sigma )
dens( prior_y )


data(Howell1)
d <- Howell1
d2 <- d[ d$age >= 18 , ]

#4M2

flist <- alist(
  height ~ dnorm( mu , sigma ) ,
  mu ~ dnorm( 0 , 10 ) ,
  sigma ~ dexp( 1 )
)

m4.1 <- quap( flist , data=d2 )

precis( m4.1 )



```

## 4M3. Translate the quap model formula below into a mathematical model definition.

y ~ dnorm( mu , sigma ),
mu <- a + b*x,
a ~ dnorm( 0 , 10 ),
b ~ dunif( 0 , 1 ),
sigma ~ dexp( 1 )

yi ~ Normal( mu, sigma)
mu = a + b*x
a ~ Normal( 0, 10 )
b ~ Uniform( 0, 1 )
sigma ~ Exponential( 1 )

## 4M4. A sample of students is measured for height each year for 3 years. After the third year, you want to fit a linear regression predicting height using year as a predictor. Write down the mathematical model definition for this regression, using any variable names and priors you choose. Be prepared to defend your choice of priors.

where yi = year of measurement
where ai = age

hi ∼ Normal(µi, σ) [likelihood]
µi = α + β*(ai-abar) [linear model]
α ∼ Normal(100, 20) [α prior]
β ∼ Log-Normal(0, 10) [β prior]
σ ∼ Uniform(0, 50) [σ prior]

```{r}

#no student should get shorter as time progresses, therefore use a log normal distribution for the slop term (beta)
sample_beta <- rlnorm( 1e4 , 0 , 10 )

dens( sample_beta )

sample_sigma <- runif( 1e4 , 0 , 50 )

dens( sample_sigma )

sample_alpha <- rnorm( 1e4, 100, 20 )

dens( sample_alpha )


# sample_mu <- rnorm( 1e4 , 0 , 10 )
# sample_sigma <- rexp( 1e4 , 1 )
# prior_y <- rnorm( 1e4 , sample_mu , sample_sigma )
# dens( prior_y )

```


##4M5. Now suppose I remind you that every student got taller each year. Does this information lead you to change your choice of priors? How?

## update the slope term (beta) to a log-normal distribution so no person has negative growth
## β ∼ Log-Normal(0, 10) [β prior]

## 4M6. Now suppose I tell you that the variance among heights for students of the same age is never more than 64cm. How does this lead you to revise your priors?

µi = α + β*(ai-abar) [linear model]
α ∼ Normal(100, 20) [α prior]
β ∼ Log-Normal(0, 10) [β prior]

## when ai - abar = 0 (students of the same age) you're left with alpha.    

```{r}
set.seed(2971)
N <- 100

a <- rnorm(N , 44 , 20)
b <- rlnorm(N , 0 , 1)

plot(
  NULL ,
  xlim = c(13, 16) ,
  ylim = c(0, 200) ,
  xlab = "age" ,
  ylab = "height"
)

abline(h = 0 , lty = 2)
abline(h = 272 , lty = 1 , lwd = 0.5)

xbar <- 15

for (i in 1:N)
  curve(
    a[i] + b[i] * (x - xbar) ,
    from = 13 ,
    to = 16 ,
    add = TRUE ,
    col = col.alpha("black", 0.2)
  )


```


## 4M7. Refit model m4.3 from the chapter, but omit the mean weight xbar this time. Compare the new model’s posterior to that of the original model. In particular, look at the covariance among the parameters. What is different? Then compare the posterior predictions of both models.

```{r,render=lemon_print}

# load data again, since it's a long way back
library(rethinking)
data(Howell1)
d <- Howell1
d2 <- d[d$age >= 18 ,]
# define the average weight, x-bar
xbar <- mean(d2$weight)
# fit model

m4.3 <- quap(alist(
  height ~ dnorm(mu , sigma) ,
  mu <- a + b * (weight - xbar) ,
  a ~ dnorm(178 , 20) ,
  b ~ dlnorm(0 , 1) ,
  sigma ~ dunif(0 , 50)
) ,
data = d2)

m4.3b <- quap(alist(
  height ~ dnorm(mu , sigma) ,
  mu <- a + b * (weight) ,
  a ~ dnorm(178 , 20) ,
  b ~ dlnorm(0 , 1) ,
  sigma ~ dunif(0 , 50)
) ,
data = d2)

precis( m4.3 )
precis( m4.3b )


```
```{r}
m4.3_vcov <- round( vcov( m4.3 ) , 3 )
m4.3_vcov
cov2cor(m4.3_vcov)

m4.3b_vcov <- round( vcov( m4.3b ) , 3 )
m4.3b_vcov
cov2cor(m4.3b_vcov)

# when you remove xbar (mean weight) alpha and beta become strongly negatively correlated

```
```{r}
plot( height ~ weight , data=d2 , col=rangi2 )
post <- extract.samples( m4.3 )
a_map <- mean(post$a)
b_map <- mean(post$b)
curve( a_map + b_map*(x - xbar) , add=TRUE )

plot( height ~ weight , data=d2 , col=rangi2 )
post <- extract.samples( m4.3b )
a_map <- mean(post$a)
b_map <- mean(post$b)
curve( a_map + b_map*(x) , add=TRUE )


N <- 10
dN <- d2[ 1:N , ]
# extract 20 samples from the posterior
post <- extract.samples(m4.3 , n = 20)
# display raw data and sample size
plot(
  dN$weight ,
  dN$height ,
  xlim = range(d2$weight) ,
  ylim = range(d2$height) ,
  col = rangi2 ,
  xlab = "weight" ,
  ylab = "height"
)
mtext(concat("N = ", N))
# plot the lines, with transparency
for (i in 1:20)
  curve(post$a[i] + post$b[i] * (x - mean(dN$weight)) ,
        col = col.alpha("black", 0.3) ,
        add = TRUE)

N <- 10
dN <- d2[ 1:N , ]
# extract 20 samples from the posterior
post <- extract.samples(m4.3b , n = 20)
# display raw data and sample size
plot(
  dN$weight ,
  dN$height ,
  xlim = range(d2$weight) ,
  ylim = range(d2$height) ,
  col = rangi2 ,
  xlab = "weight" ,
  ylab = "height"
)
mtext(concat("N = ", N))
# plot the lines, with transparency
for (i in 1:20)
  curve(post$a[i] + post$b[i] * (x) ,
        col = col.alpha("black", 0.3) ,
        add = TRUE)

# the posterior predictions barely shift! why?

```

